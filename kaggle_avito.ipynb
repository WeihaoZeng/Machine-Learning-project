{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avito Demand Prediction Challenge\n",
    "\n",
    "### This is our final aggregated and cleaned notebook. Some of the cells didn't run in this notebook because the EC2 instance breaks down frequently, but our final resuts were generated from the pervious versions of this notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h2o\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator \n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch \n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "from h2o.estimators.xgboost import H2OXGBoostEstimator\n",
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators.glrm import H2OGeneralizedLowRankEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to read in the data, and for the activation_date we are going to read in as date type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"train.csv\", parse_dates=[\"activation_date\"])\n",
    "test = pd.read_csv(\"test.csv\", parse_dates=[\"activation_date\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below we splited our data into train, validation, train stack, and validation stack. We need different pairs of trainning and validation set to train our base models and stack model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base, stack= train_test_split( train_raw, test_size=0.5,random_state=123)\n",
    "train_df,valid_df=train_test_split( base, test_size=0.3,random_state=123)\n",
    "train_stack,valid_stack=train_test_split( stack, test_size=0.3,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning: \n",
    "### 1. We are going to clean the data to first fill the NA values with empty space. We don't fill with 'None' because we are going count the words and the length.\n",
    "### 2. For the column price, we decided to fill the NA values with random choices from the existing values and add some noise to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for data in [train_df,valid_df,train_stack,valid_stack,test]:\n",
    "    data['description'] = data['description'].fillna(' ')\n",
    "    data['title'] = data['title'].fillna(' ')\n",
    "    data['price']=data['price'].fillna(np.random.choice(data['price'].dropna()+np.random.normal(0,50)))\n",
    "    for column in ['param_1','param_2','param_3','image','image_top_1']:\n",
    "        data[column]=data[column].fillna(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering\n",
    "### 1. We are going to add the day, month, and week column to the data set. We think selling stuff at different days of the week and different weeks of the month will affect the chance of selling. \n",
    "### 2. We also added the lenth of the description as new columns.\n",
    "### 3. We also changed the weekday variable to english, so it is be a categorical variable now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for data in [train_df,valid_df,train_stack,valid_stack,test]:\n",
    "\n",
    "    data['weekday'] = data.activation_date.dt.weekday\n",
    "    data['month'] = data.activation_date.dt.month\n",
    "    data['day'] = data.activation_date.dt.day\n",
    "    data['week'] = data.activation_date.dt.week \n",
    "\n",
    "# length of description\n",
    "    data['description_len'] = data['description'].apply(lambda x : len(x.split()))\n",
    "\n",
    "# length of title\n",
    "    data['title_len'] = data['title'].apply(lambda x : len(x.split()))\n",
    "\n",
    "# param_combined and its length\n",
    "    data['param_combined'] = data.apply(lambda row: ' '.join([str(row['param_1']), str(row['param_2']),  str(row['param_3'])]), axis=1)\n",
    "    data['param_combined'] = data['param_combined'].fillna(\"none\")\n",
    "    data['param_combined_len'] = data['param_combined'].apply(lambda x : len(x.split()))\n",
    "\n",
    "# charater len of text columns\n",
    "    data['description_char'] = data['description'].apply(len)\n",
    "    data['title_char'] = data['title'].apply(len)\n",
    "    data['param_char'] = data['param_combined'].apply(len)\n",
    "\n",
    "# english mapped of weekday\n",
    "    daymap = {0:'Sun', 1:'Mon', 2:'Tue', 3:'Wed', 4:'Thu', 5:'Fri', 6:'Sat'}\n",
    "    data['weekday_en'] = data['weekday'].apply(lambda x : daymap[x])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                         object\n",
       "user_id                         object\n",
       "region                          object\n",
       "city                            object\n",
       "parent_category_name            object\n",
       "category_name                   object\n",
       "param_1                         object\n",
       "param_2                         object\n",
       "param_3                         object\n",
       "title                           object\n",
       "description                     object\n",
       "price                          float64\n",
       "item_seq_number                  int64\n",
       "activation_date         datetime64[ns]\n",
       "user_type                       object\n",
       "image                           object\n",
       "image_top_1                     object\n",
       "deal_probability               float64\n",
       "weekday                          int64\n",
       "month                            int64\n",
       "day                              int64\n",
       "week                             int64\n",
       "description_len                  int64\n",
       "title_len                        int64\n",
       "param_combined                  object\n",
       "param_combined_len               int64\n",
       "description_char                 int64\n",
       "title_char                       int64\n",
       "param_char                       int64\n",
       "weekday_en                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>description_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>param_combined</th>\n",
       "      <th>param_combined_len</th>\n",
       "      <th>description_char</th>\n",
       "      <th>title_char</th>\n",
       "      <th>param_char</th>\n",
       "      <th>weekday_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>483951</th>\n",
       "      <td>270c38770ced</td>\n",
       "      <td>40322123588f</td>\n",
       "      <td>Удмуртия</td>\n",
       "      <td>Воткинск</td>\n",
       "      <td>Животные</td>\n",
       "      <td>Другие животные</td>\n",
       "      <td>С/х животные</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Продам Вьетнамского хряка производителя</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>С/х животные</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368194</th>\n",
       "      <td>284cce5ff1bf</td>\n",
       "      <td>e137387ba975</td>\n",
       "      <td>Краснодарский край</td>\n",
       "      <td>Краснодар</td>\n",
       "      <td>Хобби и отдых</td>\n",
       "      <td>Спорт и отдых</td>\n",
       "      <td>Другое</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Лонда</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Другое</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145682</th>\n",
       "      <td>734303f67075</td>\n",
       "      <td>3d001ae3dcdf</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>Дома, дачи, коттеджи</td>\n",
       "      <td>Продам</td>\n",
       "      <td>Дом</td>\n",
       "      <td></td>\n",
       "      <td>Дом 67 м² на участке 1.7 сот.</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>Продам Дом</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>Wed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311019</th>\n",
       "      <td>fa42898b5df7</td>\n",
       "      <td>034a1464686b</td>\n",
       "      <td>Воронежская область</td>\n",
       "      <td>Воронеж</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Ремонт и строительство</td>\n",
       "      <td>Стройматериалы</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Трубы профильные для заборов и металлоконструкций</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Стройматериалы</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882399</th>\n",
       "      <td>f201d565c36f</td>\n",
       "      <td>c04f9562479f</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>Женская одежда</td>\n",
       "      <td>Платья и юбки</td>\n",
       "      <td>42–44 (S)</td>\n",
       "      <td>Новое джинсовое платье</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>Женская одежда Платья и юбки 42–44 (S)</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>Wed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              item_id       user_id               region            city  \\\n",
       "483951   270c38770ced  40322123588f             Удмуртия        Воткинск   \n",
       "1368194  284cce5ff1bf  e137387ba975   Краснодарский край       Краснодар   \n",
       "145682   734303f67075  3d001ae3dcdf   Ростовская область  Ростов-на-Дону   \n",
       "1311019  fa42898b5df7  034a1464686b  Воронежская область         Воронеж   \n",
       "882399   f201d565c36f  c04f9562479f   Ростовская область  Ростов-на-Дону   \n",
       "\n",
       "        parent_category_name              category_name         param_1  \\\n",
       "483951              Животные            Другие животные    С/х животные   \n",
       "1368194        Хобби и отдых              Спорт и отдых          Другое   \n",
       "145682          Недвижимость       Дома, дачи, коттеджи          Продам   \n",
       "1311019      Для дома и дачи     Ремонт и строительство  Стройматериалы   \n",
       "882399           Личные вещи  Одежда, обувь, аксессуары  Женская одежда   \n",
       "\n",
       "               param_2    param_3  \\\n",
       "483951                              \n",
       "1368194                             \n",
       "145682             Дом              \n",
       "1311019                             \n",
       "882399   Платья и юбки  42–44 (S)   \n",
       "\n",
       "                                                     title     ...     day  \\\n",
       "483951             Продам Вьетнамского хряка производителя     ...      26   \n",
       "1368194                                              Лонда     ...      17   \n",
       "145682                       Дом 67 м² на участке 1.7 сот.     ...      16   \n",
       "1311019  Трубы профильные для заборов и металлоконструкций     ...      21   \n",
       "882399                              Новое джинсовое платье     ...      16   \n",
       "\n",
       "         week  description_len title_len  \\\n",
       "483951     12               10         4   \n",
       "1368194    11                4         1   \n",
       "145682     11               14         7   \n",
       "1311019    12                4         6   \n",
       "882399     11               15         3   \n",
       "\n",
       "                                 param_combined param_combined_len  \\\n",
       "483951                         С/х животные                      2   \n",
       "1368194                              Другое                      1   \n",
       "145682                             Продам Дом                    2   \n",
       "1311019                      Стройматериалы                      1   \n",
       "882399   Женская одежда Платья и юбки 42–44 (S)                  7   \n",
       "\n",
       "        description_char  title_char  param_char  weekday_en  \n",
       "483951                93          39          16         Sat  \n",
       "1368194               28           5          10         Thu  \n",
       "145682                99          29          12         Wed  \n",
       "1311019              178          49          18         Mon  \n",
       "882399                93          22          38         Wed  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After checking each column and its data type, we decided to correct the miss matched columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for data in [train_df,valid_df,train_stack,valid_stack,test]:\n",
    "    for column in [\"item_seq_number\",\"image_top_1\",\"weekday\",\"week\",\"day\",\"month\"]:\n",
    "        data[column]=data[column].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(601369, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(601369, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## text engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We believe that the Ad description will affct the deal probability greatly, so we are going to do text engineering to make the description as part of our dataset that can be used for our final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We are going to add columns by each word and count the occurence of the word for each row. Since we are going to find the effect of those popular and meaningful word, we believe these words would show multiple times, then it would be convinient and fast to find these words using 10% sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random=train_df[[\"title\",\"description\"]].sample(frac=0.1, replace=False,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60137, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are creating a list, and add all the lowered words without punctuations and digits to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105633"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content= []\n",
    "\n",
    "#replace punctuation with space\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "\n",
    "#remove digits\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "\n",
    "\n",
    "#split the words and add each word to the list\n",
    "for words in random[\"description\"]:\n",
    "    word=words.translate(remove_digits).translate(translator).lower().split()\n",
    "    content+=word\n",
    "    \n",
    "for words in random[\"title\"]:\n",
    "    word=words.translate(remove_digits).translate(translator).lower().split()\n",
    "    content+=word\n",
    "\n",
    "# check how many unique content we have\n",
    "u_content = list(set(content))\n",
    "\n",
    "len(u_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a lot more words than what we can use for our final model, so below we are going to select some of them according to frequency that the word appears. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts=Counter(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105633.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.105838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>271.019437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50186.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word\n",
       "count  105633.000000\n",
       "mean       15.105838\n",
       "std       271.019437\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         4.000000\n",
       "max     50186.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a word dictionary, and store the key and values\n",
    "\n",
    "words = list((v) for k, v in counts.items())\n",
    "word=pd.DataFrame({'word':words})\n",
    "word.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because there are too many words, we are only going to choose some of them, which could be useful to predit deal probability, as our new variables. From the pervious output we can see that the frenquency of the words are extremely skewed, so we are going to choose the ones that are popular, but not the most popular, because we believe the ones that have the highest counts are most likely to be generic verbs. Hence, we chose the quantile of 0.989 to 0.991. We do not want to have too many column, so we chose a small fraction of the popular words to be used in our model. Then we check these selected words and find they are quite meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowerbound=int(word.quantile(.989))\n",
    "higherbound=int(word.quantile(.991))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_word = dict((k, v) for k, v in counts.items() if  v in range(lowerbound,higherbound)  )\n",
    "keep_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keep_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### After getting all the new words and their counts as its own dataframe, we are going to combine them with the orginal dataframe. In the combined dataframe, each row will have their orignals information and the count of popular words they have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_count=set(keep_word)\n",
    "to_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "\n",
    "\n",
    "for data in [train_df]:\n",
    "    \n",
    "    #create lists to store the word list\n",
    "    titlelist=[]\n",
    "    descriptionlist=[]\n",
    "\n",
    "    \n",
    "    #for each row, we translate the content into sperated words\n",
    "    for i in range(0,len(data[\"title\"])):\n",
    "        titlelist.append(data.loc[data.index[i], 'title'].translate(remove_digits).translate(translator).lower())\n",
    "    \n",
    "    for i in range(0,len(data[\"description\"])):\n",
    "        descriptionlist.append(data.loc[data.index[i], 'description'].translate(remove_digits).translate(translator).lower())\n",
    "    \n",
    "    # for selected word in each row, count the frequency of that word and store the value in the corresponding word column\n",
    "    vec = CountVectorizer(vocabulary=to_count)\n",
    "    X = vec.fit_transform(titlelist)\n",
    "    title = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "\n",
    "    X = vec.fit_transform(descriptionlist)\n",
    "    des = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "    text = title.add(des, fill_value=0)\n",
    "    \n",
    "    #add row index to combine two dataframe\n",
    "    data['index'] = range(len(data))\n",
    "    text['index']= range(len(text)) \n",
    "    \n",
    "    train1=pd.merge(data,text,on=\"index\")\n",
    "    del train1['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for data in [valid_df]:\n",
    "    \n",
    "    #create lists to store the word \n",
    "    titlelist=[]\n",
    "    descriptionlist=[]\n",
    "\n",
    "    \n",
    "    #for each row, we translate the content into sperated words\n",
    "    for i in range(0,len(data[\"title\"])):\n",
    "        titlelist.append(data.loc[data.index[i], 'title'].translate(remove_digits).translate(translator).lower())\n",
    "    \n",
    "    for i in range(0,len(data[\"description\"])):\n",
    "        descriptionlist.append(data.loc[data.index[i], 'description'].translate(remove_digits).translate(translator).lower())\n",
    "    \n",
    "    # for selected word in each row, count the frequency of that word and store the value in the corresponding word column\n",
    "    vec = CountVectorizer(vocabulary=to_count)\n",
    "    X = vec.fit_transform(titlelist)\n",
    "    title = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "\n",
    "    X = vec.fit_transform(descriptionlist)\n",
    "    des = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "    text = title.add(des, fill_value=0)\n",
    "    \n",
    "    #add row index to combine two dataframe\n",
    "    data['index'] = range(len(data))\n",
    "    text['index']= range(len(text)) \n",
    "    \n",
    "    valid1=pd.merge(data,text,on=\"index\")\n",
    "    del valid1['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for data in [train_stack]:\n",
    "    \n",
    "    #create lists to store the word \n",
    "    titlelist=[]\n",
    "    descriptionlist=[]\n",
    "\n",
    "    \n",
    "    #for each row, we translate the content into sperated words\n",
    "\n",
    "    for i in range(0,len(data[\"title\"])):\n",
    "        titlelist.append(data.loc[data.index[i], 'title'].translate(remove_digits).translate(translator).lower())\n",
    "    \n",
    "    for i in range(0,len(data[\"description\"])):\n",
    "        descriptionlist.append(data.loc[data.index[i], 'description'].translate(remove_digits).translate(translator).lower())\n",
    "    \n",
    "    # for selected word in each row, count the frequency of that word and store the value in the corresponding word column\n",
    "    vec = CountVectorizer(vocabulary=to_count)\n",
    "    X = vec.fit_transform(titlelist)\n",
    "    title = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "\n",
    "    X = vec.fit_transform(descriptionlist)\n",
    "    des = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "    text = title.add(des, fill_value=0)\n",
    "    \n",
    "    #add row index to combine two dataframe\n",
    "    data['index'] = range(len(data))\n",
    "    text['index']= range(len(text)) \n",
    "    \n",
    "    train2=pd.merge(data,text,on=\"index\")\n",
    "    del train2['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for data in [valid_stack]:\n",
    "    \n",
    "    #create lists to store the word \n",
    "    titlelist=[]\n",
    "    descriptionlist=[]\n",
    "\n",
    "    \n",
    "    #for each row, we translate the content into sperated words\n",
    "\n",
    "    for i in range(0,len(data[\"title\"])):\n",
    "        titlelist.append(data.loc[data.index[i], 'title'].translate(remove_digits).translate(translator).lower())\n",
    "    \n",
    "    for i in range(0,len(data[\"description\"])):\n",
    "        descriptionlist.append(data.loc[data.index[i], 'description'].translate(remove_digits).translate(translator).lower())\n",
    "    \n",
    "    # for selected word in each row, count the frequency of that word and store the value in the corresponding word column\n",
    "    vec = CountVectorizer(vocabulary=to_count)\n",
    "    X = vec.fit_transform(titlelist)\n",
    "    title = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "\n",
    "    X = vec.fit_transform(descriptionlist)\n",
    "    des = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "    text = title.add(des, fill_value=0)\n",
    "    \n",
    "    #add row index to combine two dataframe\n",
    "    data['index'] = range(len(data))\n",
    "    text['index']= range(len(text)) \n",
    "    \n",
    "    valid2=pd.merge(data,text,on=\"index\")\n",
    "    del valid2['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in [test]:\n",
    "    \n",
    "    #create lists to store the word \n",
    "    titlelist=[]\n",
    "    descriptionlist=[]\n",
    "\n",
    "    \n",
    "    #for each row, we translate the content into sperated words\n",
    "\n",
    "    for i in range(0,len(data[\"title\"])):\n",
    "        titlelist.append(data.loc[data.index[i], 'title'].translate(remove_digits).translate(translator).lower())\n",
    "    \n",
    "    for i in range(0,len(data[\"description\"])):\n",
    "        descriptionlist.append(data.loc[data.index[i], 'description'].translate(remove_digits).translate(translator).lower())\n",
    "    \n",
    "    # for selected word in each row, count the frequency of that word and store the value in the corresponding word column\n",
    "    vec = CountVectorizer(vocabulary=to_count)\n",
    "    X = vec.fit_transform(titlelist)\n",
    "    title = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "\n",
    "    X = vec.fit_transform(descriptionlist)\n",
    "    des = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "    text = title.add(des, fill_value=0)\n",
    "    \n",
    "    #add row index to combine two dataframe\n",
    "    data['index'] = range(len(data))\n",
    "    text['index']= range(len(text)) \n",
    "    \n",
    "    test_new=pd.merge(data,text,on=\"index\")\n",
    "    del test_new['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>ходунки</th>\n",
       "      <th>центра</th>\n",
       "      <th>цену</th>\n",
       "      <th>черные</th>\n",
       "      <th>числе</th>\n",
       "      <th>шерсть</th>\n",
       "      <th>шуба</th>\n",
       "      <th>электро</th>\n",
       "      <th>этажного</th>\n",
       "      <th>ядра</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270c38770ced</td>\n",
       "      <td>40322123588f</td>\n",
       "      <td>Удмуртия</td>\n",
       "      <td>Воткинск</td>\n",
       "      <td>Животные</td>\n",
       "      <td>Другие животные</td>\n",
       "      <td>С/х животные</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Продам Вьетнамского хряка производителя</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284cce5ff1bf</td>\n",
       "      <td>e137387ba975</td>\n",
       "      <td>Краснодарский край</td>\n",
       "      <td>Краснодар</td>\n",
       "      <td>Хобби и отдых</td>\n",
       "      <td>Спорт и отдых</td>\n",
       "      <td>Другое</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Лонда</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734303f67075</td>\n",
       "      <td>3d001ae3dcdf</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>Дома, дачи, коттеджи</td>\n",
       "      <td>Продам</td>\n",
       "      <td>Дом</td>\n",
       "      <td></td>\n",
       "      <td>Дом 67 м² на участке 1.7 сот.</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fa42898b5df7</td>\n",
       "      <td>034a1464686b</td>\n",
       "      <td>Воронежская область</td>\n",
       "      <td>Воронеж</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Ремонт и строительство</td>\n",
       "      <td>Стройматериалы</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Трубы профильные для заборов и металлоконструкций</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f201d565c36f</td>\n",
       "      <td>c04f9562479f</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>Женская одежда</td>\n",
       "      <td>Платья и юбки</td>\n",
       "      <td>42–44 (S)</td>\n",
       "      <td>Новое джинсовое платье</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id               region            city  \\\n",
       "0  270c38770ced  40322123588f             Удмуртия        Воткинск   \n",
       "1  284cce5ff1bf  e137387ba975   Краснодарский край       Краснодар   \n",
       "2  734303f67075  3d001ae3dcdf   Ростовская область  Ростов-на-Дону   \n",
       "3  fa42898b5df7  034a1464686b  Воронежская область         Воронеж   \n",
       "4  f201d565c36f  c04f9562479f   Ростовская область  Ростов-на-Дону   \n",
       "\n",
       "  parent_category_name              category_name         param_1  \\\n",
       "0             Животные            Другие животные    С/х животные   \n",
       "1        Хобби и отдых              Спорт и отдых          Другое   \n",
       "2         Недвижимость       Дома, дачи, коттеджи          Продам   \n",
       "3      Для дома и дачи     Ремонт и строительство  Стройматериалы   \n",
       "4          Личные вещи  Одежда, обувь, аксессуары  Женская одежда   \n",
       "\n",
       "         param_2    param_3  \\\n",
       "0                             \n",
       "1                             \n",
       "2            Дом              \n",
       "3                             \n",
       "4  Платья и юбки  42–44 (S)   \n",
       "\n",
       "                                               title ...  ходунки  центра  \\\n",
       "0            Продам Вьетнамского хряка производителя ...        0       0   \n",
       "1                                              Лонда ...        0       0   \n",
       "2                      Дом 67 м² на участке 1.7 сот. ...        0       0   \n",
       "3  Трубы профильные для заборов и металлоконструкций ...        0       0   \n",
       "4                             Новое джинсовое платье ...        0       0   \n",
       "\n",
       "  цену черные числе шерсть шуба  электро этажного ядра  \n",
       "0    0      0     0      0    0        0        0    0  \n",
       "1    0      0     0      0    0        0        0    0  \n",
       "2    0      0     0      0    0        0        0    0  \n",
       "3    0      0     0      0    0        0        0    0  \n",
       "4    0      0     0      0    0        0        0    0  \n",
       "\n",
       "[5 rows x 245 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## We used the function tfidvectorizer to convert a collection of raw documents to a matrix of TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "for data in [train1,valid1,train2,valid2,test_new]:\n",
    "    tfidf = TfidfVectorizer(max_features=1000)\n",
    "    tfidf_train = np.array(tfidf.fit_transform(data['description']).todense(), dtype=np.float16)\n",
    "    for i in range(1000):\n",
    "        data['tfidf_' + str(i)] = tfidf_train[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order not to let any large numeric values to dominate our model, we are going to standarlize our numeric values by transform them its z-scores. First we have to find the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'deal_probability', 'description_len', 'title_len',\n",
       "       'param_combined_len', 'description_char', 'title_char', 'param_char',\n",
       "       'acer', 'amd',\n",
       "       ...\n",
       "       'tfidf_990', 'tfidf_991', 'tfidf_992', 'tfidf_993', 'tfidf_994',\n",
       "       'tfidf_995', 'tfidf_996', 'tfidf_997', 'tfidf_998', 'tfidf_999'],\n",
       "      dtype='object', length=1223)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric = train1.describe().columns\n",
    "numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1222"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_std=list(set(numeric)-set([\"deal_probability\"]))\n",
    "len(to_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in [train1,valid1,train2,valid2,test_new]:\n",
    "    data[to_std] =(data[to_std] - data[to_std].mean())/data[to_std].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_990</th>\n",
       "      <th>tfidf_991</th>\n",
       "      <th>tfidf_992</th>\n",
       "      <th>tfidf_993</th>\n",
       "      <th>tfidf_994</th>\n",
       "      <th>tfidf_995</th>\n",
       "      <th>tfidf_996</th>\n",
       "      <th>tfidf_997</th>\n",
       "      <th>tfidf_998</th>\n",
       "      <th>tfidf_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270c38770ced</td>\n",
       "      <td>40322123588f</td>\n",
       "      <td>Удмуртия</td>\n",
       "      <td>Воткинск</td>\n",
       "      <td>Животные</td>\n",
       "      <td>Другие животные</td>\n",
       "      <td>С/х животные</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Продам Вьетнамского хряка производителя</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0467</td>\n",
       "      <td>-0.063602</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>-0.081489</td>\n",
       "      <td>-0.109711</td>\n",
       "      <td>-0.0525</td>\n",
       "      <td>-0.059849</td>\n",
       "      <td>-0.052422</td>\n",
       "      <td>-0.06233</td>\n",
       "      <td>-0.052742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284cce5ff1bf</td>\n",
       "      <td>e137387ba975</td>\n",
       "      <td>Краснодарский край</td>\n",
       "      <td>Краснодар</td>\n",
       "      <td>Хобби и отдых</td>\n",
       "      <td>Спорт и отдых</td>\n",
       "      <td>Другое</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Лонда</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0467</td>\n",
       "      <td>-0.063602</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>-0.081489</td>\n",
       "      <td>-0.109711</td>\n",
       "      <td>-0.0525</td>\n",
       "      <td>-0.059849</td>\n",
       "      <td>-0.052422</td>\n",
       "      <td>-0.06233</td>\n",
       "      <td>-0.052742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734303f67075</td>\n",
       "      <td>3d001ae3dcdf</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>Дома, дачи, коттеджи</td>\n",
       "      <td>Продам</td>\n",
       "      <td>Дом</td>\n",
       "      <td></td>\n",
       "      <td>Дом 67 м² на участке 1.7 сот.</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0467</td>\n",
       "      <td>-0.063602</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>-0.081489</td>\n",
       "      <td>-0.109711</td>\n",
       "      <td>-0.0525</td>\n",
       "      <td>-0.059849</td>\n",
       "      <td>-0.052422</td>\n",
       "      <td>-0.06233</td>\n",
       "      <td>-0.052742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fa42898b5df7</td>\n",
       "      <td>034a1464686b</td>\n",
       "      <td>Воронежская область</td>\n",
       "      <td>Воронеж</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Ремонт и строительство</td>\n",
       "      <td>Стройматериалы</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Трубы профильные для заборов и металлоконструкций</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0467</td>\n",
       "      <td>-0.063602</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>-0.081489</td>\n",
       "      <td>-0.109711</td>\n",
       "      <td>-0.0525</td>\n",
       "      <td>-0.059849</td>\n",
       "      <td>-0.052422</td>\n",
       "      <td>-0.06233</td>\n",
       "      <td>-0.052742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f201d565c36f</td>\n",
       "      <td>c04f9562479f</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>Женская одежда</td>\n",
       "      <td>Платья и юбки</td>\n",
       "      <td>42–44 (S)</td>\n",
       "      <td>Новое джинсовое платье</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0467</td>\n",
       "      <td>-0.063602</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>-0.081489</td>\n",
       "      <td>-0.109711</td>\n",
       "      <td>-0.0525</td>\n",
       "      <td>-0.059849</td>\n",
       "      <td>-0.052422</td>\n",
       "      <td>-0.06233</td>\n",
       "      <td>-0.052742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id               region            city  \\\n",
       "0  270c38770ced  40322123588f             Удмуртия        Воткинск   \n",
       "1  284cce5ff1bf  e137387ba975   Краснодарский край       Краснодар   \n",
       "2  734303f67075  3d001ae3dcdf   Ростовская область  Ростов-на-Дону   \n",
       "3  fa42898b5df7  034a1464686b  Воронежская область         Воронеж   \n",
       "4  f201d565c36f  c04f9562479f   Ростовская область  Ростов-на-Дону   \n",
       "\n",
       "  parent_category_name              category_name         param_1  \\\n",
       "0             Животные            Другие животные    С/х животные   \n",
       "1        Хобби и отдых              Спорт и отдых          Другое   \n",
       "2         Недвижимость       Дома, дачи, коттеджи          Продам   \n",
       "3      Для дома и дачи     Ремонт и строительство  Стройматериалы   \n",
       "4          Личные вещи  Одежда, обувь, аксессуары  Женская одежда   \n",
       "\n",
       "         param_2    param_3  \\\n",
       "0                             \n",
       "1                             \n",
       "2            Дом              \n",
       "3                             \n",
       "4  Платья и юбки  42–44 (S)   \n",
       "\n",
       "                                               title    ...    tfidf_990  \\\n",
       "0            Продам Вьетнамского хряка производителя    ...      -0.0467   \n",
       "1                                              Лонда    ...      -0.0467   \n",
       "2                      Дом 67 м² на участке 1.7 сот.    ...      -0.0467   \n",
       "3  Трубы профильные для заборов и металлоконструкций    ...      -0.0467   \n",
       "4                             Новое джинсовое платье    ...      -0.0467   \n",
       "\n",
       "   tfidf_991 tfidf_992 tfidf_993 tfidf_994 tfidf_995 tfidf_996  tfidf_997  \\\n",
       "0  -0.063602 -0.089416 -0.081489 -0.109711   -0.0525 -0.059849  -0.052422   \n",
       "1  -0.063602 -0.089416 -0.081489 -0.109711   -0.0525 -0.059849  -0.052422   \n",
       "2  -0.063602 -0.089416 -0.081489 -0.109711   -0.0525 -0.059849  -0.052422   \n",
       "3  -0.063602 -0.089416 -0.081489 -0.109711   -0.0525 -0.059849  -0.052422   \n",
       "4  -0.063602 -0.089416 -0.081489 -0.109711   -0.0525 -0.059849  -0.052422   \n",
       "\n",
       "  tfidf_998 tfidf_999  \n",
       "0  -0.06233 -0.052742  \n",
       "1  -0.06233 -0.052742  \n",
       "2  -0.06233 -0.052742  \n",
       "3  -0.06233 -0.052742  \n",
       "4  -0.06233 -0.052742  \n",
       "\n",
       "[5 rows x 1245 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete those unwanted column and needless objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in [train1,valid1,train2,valid2,test_new]:\n",
    "    del data['activation_date']\n",
    "    del data['title']\n",
    "    del data['description']\n",
    "    del data['image']\n",
    "    del data['image_top_1']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in [train_df,valid_df,train_stack,valid_stack,test,train_raw,base,stack]:\n",
    "    del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Below we are going to use H2O to train our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>8 hours 43 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.18.0.11</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 5 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_ec2_user_c44jru</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>16.19 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.1 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         8 hours 43 mins\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.18.0.11\n",
       "H2O cluster version age:    1 month and 5 days\n",
       "H2O cluster name:           H2O_from_python_ec2_user_c44jru\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    16.19 Gb\n",
       "H2O cluster total cores:    32\n",
       "H2O cluster allowed cores:  32\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.1 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our target and input\n",
    "\n",
    "y = 'deal_probability'\n",
    "X = [name for name in train1.columns if name not in [y]]\n",
    "\n",
    "#Convert pandas data frame to H2O data frame\n",
    "train_b = h2o.H2OFrame(train1)\n",
    "valid_b = h2o.H2OFrame(valid1)\n",
    "train_s = h2o.H2OFrame(train2)\n",
    "valid_s = h2o.H2OFrame(valid2)\n",
    "test_final = h2o.H2OFrame(test_new)\n",
    "\n",
    "\n",
    "# remove the first row because we find the first row is the header of pandas data frame.\n",
    "train_b=train_b[1:,:]\n",
    "train_s=train_s[1:,:]\n",
    "valid_s=valid_s[1:,:]\n",
    "valid_b=valid_b[1:,:]\n",
    "test_final = test_final[1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We created this function to help generate the final csv output, so after each model, we can use this function to get each model's output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def gen_submission(preds,name,test=test):\n",
    "\n",
    "    # covert H2O data frame back to pandas data frame\n",
    "    # combine two columns from two pandas data frames\n",
    "    # change the column name and make sure the id is string so that we can summit the result\n",
    "    result = preds.as_data_frame()\n",
    "    sub = pd.concat([test_new['item_id'],result[\"predict\"] ], axis = 1)\n",
    "    sub.columns = ['item_id', 'deal_probability']\n",
    "    sub['item_id']=sub['item_id'].astype('str')\n",
    "    \n",
    "    # name and save file for submission\n",
    "    sub_fname =  str(name) + '.csv'\n",
    "    sub.to_csv(sub_fname,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we train on the base models. And we set 10 folds cross-validation to stack models later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = H2ORandomForestEstimator(\n",
    "    # Stops fitting new trees when 10-tree rolling average is within 0.00001\n",
    "    stopping_rounds = 10,\n",
    "    stopping_tolerance = 0.00001,\n",
    "    stopping_metric = 'auto',\n",
    "    score_each_iteration = True,\n",
    "    balance_classes = True,\n",
    "    nfolds=10,\n",
    "    keep_cross_validation_predictions=True,\n",
    "    seed = 123)\n",
    "\n",
    "hyper_parameters = {'ntrees':list(range(0, 1000, 20)),\n",
    "                    'max_depth':list(range(1, 100, 3))}\n",
    "\n",
    "            \n",
    "# define search strategy\n",
    "search_criteria = {'strategy':'RandomDiscrete',\n",
    "                   'max_models':100,\n",
    "                   'max_runtime_secs':600,\n",
    "                   \"stopping_rounds\": 10,\n",
    "                   \"stopping_tolerance\": 0.00001,\n",
    "                   \"stopping_metric\": \"auto\"}\n",
    "  \n",
    "\n",
    "gsearch = H2OGridSearch(estimator,\n",
    "                        hyper_params=hyper_parameters,\n",
    "                        search_criteria=search_criteria)\n",
    "\n",
    "\n",
    "    \n",
    "gsearch.train(x=X,\n",
    "              y=y,\n",
    "              training_frame=train_b,\n",
    "              validation_frame=valid_b)\n",
    "\n",
    "# show grid search results\n",
    "gsearch.show()\n",
    "\n",
    "# select best model\n",
    "rf_model = gsearch.get_grid()[0]\n",
    "\n",
    "# print model information\n",
    "rf_model\n",
    "\n",
    "rf_preds1_test = rf_model.predict(test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_submission(rf_preds1_test,\"rf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define random grid search parameters\n",
    "hyper_parameters = {'hidden':[[1000, 320], [180, 190], [320, 160, 80], [200], \n",
    "                              [50, 50, 50, 50],[10,20,30,40],[500,400,300,200]],\n",
    "                    # We need L1 and L2 because we have many columns and some of them are correlated\n",
    "                    'l1':[s/1e3 for s in range(0, 1000, 10)],\n",
    "                    'l2':[s/1e4 for s in range(0, 1000, 100)],\n",
    "                    'input_dropout_ratio':[s/1e2 for s in range(0, 20, 2)]}\n",
    "\n",
    "# define search strategy\n",
    "search_criteria = {'strategy':'RandomDiscrete',\n",
    "                   'max_models':100,\n",
    "                   'max_runtime_secs':600}\n",
    "\n",
    "# initialize grid search\n",
    "gsearch = H2OGridSearch(H2ODeepLearningEstimator(nfolds=10,\n",
    "                                                 keep_cross_validation_predictions=True,\n",
    "                                                 seed = 123),\n",
    "                        hyper_params=hyper_parameters,\n",
    "                        search_criteria=search_criteria)\n",
    "\n",
    "# execute training w/ grid search\n",
    "gsearch.train(x=X,\n",
    "              y=y,\n",
    "              training_frame=train_b,\n",
    "              validation_frame=valid_b,\n",
    "              activation='TanhWithDropout',\n",
    "             adaptive_rate=True,\n",
    "             max_w2=10)\n",
    "\n",
    "# show grid search results\n",
    "gsearch.show()\n",
    "\n",
    "# select best model\n",
    "nn_model = gsearch.get_grid()[0]\n",
    "\n",
    "# print model information\n",
    "nn_model\n",
    "\n",
    "nn_preds1_test = nn_model.predict(test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_submission(nn_preds1_test,\"nn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyper_parameters = {'ntrees':list(range(0, 1000, 20)),\n",
    "                    'max_depth':list(range(1, 100, 3)),\n",
    "                    'sample_rate':[s/float(10) for s in range(1, 11)],\n",
    "                    'col_sample_rate':[s/float(10) for s in range(1, 11)]}\n",
    "\n",
    "# define search strategy\n",
    "search_criteria = {'strategy':'RandomDiscrete',\n",
    "                   'max_models':100,\n",
    "                   'max_runtime_secs':600}\n",
    "\n",
    "# initialize grid search\n",
    "gsearch = H2OGridSearch(H2OGradientBoostingEstimator(\n",
    "                        nfolds=10,\n",
    "                        keep_cross_validation_predictions=True,\n",
    "                        seed = 123),\n",
    "                        hyper_params=hyper_parameters,\n",
    "                        search_criteria=search_criteria)\n",
    "gsearch.train(x=X,\n",
    "              y=y,\n",
    "              training_frame=train_b,\n",
    "              validation_frame=valid_b)\n",
    "\n",
    "# show grid search results\n",
    "gsearch.show()\n",
    "\n",
    "# select best model\n",
    "gbm_model = gsearch.get_grid()[0]\n",
    "\n",
    "# print model information\n",
    "gbm_model\n",
    "\n",
    "gbm_preds1_test = gbm_model.predict(test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_submission(gbm_preds1_test,\"gbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = H2ORandomForestEstimator(\n",
    "    # Stops fitting new trees when 10-tree rolling average is within 0.00001\n",
    "    stopping_rounds = 10,\n",
    "    stopping_tolerance = 0.001,\n",
    "    stopping_metric = 'auto',\n",
    "    score_each_iteration = True,\n",
    "    balance_classes = True,\n",
    "    nfolds=10,\n",
    "    keep_cross_validation_predictions=True,\n",
    "    seed = 123,\n",
    "    histogram_type='random')\n",
    "\n",
    "hyper_parameters = {'ntrees':list(range(0, 1000, 20)),\n",
    "                    'max_depth':list(range(1, 50, 3))}\n",
    "\n",
    "            \n",
    "# define search strategy\n",
    "search_criteria = {'strategy':'RandomDiscrete',\n",
    "                   'max_models':100,\n",
    "                   'max_runtime_secs':60,\n",
    "                   \"stopping_rounds\": 10,\n",
    "                   \"stopping_tolerance\": 0.001,\n",
    "                   \"stopping_metric\": \"auto\"}\n",
    "  \n",
    "\n",
    "gsearch = H2OGridSearch(estimator,\n",
    "                        hyper_params=hyper_parameters,\n",
    "                        search_criteria=search_criteria)\n",
    "\n",
    "\n",
    "    \n",
    "gsearch.train(x=X,\n",
    "              y=y,\n",
    "              training_frame=train_b,\n",
    "              validation_frame=valid_b)\n",
    "\n",
    "# show grid search results\n",
    "gsearch.show()\n",
    "\n",
    "# select best model\n",
    "ert_model = gsearch.get_grid()[0]\n",
    "\n",
    "# print model information\n",
    "ert_model\n",
    "\n",
    "ert_preds1_test = ert_model.predict(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_submission(ert_preds1_test,\"ert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## After we get the results from random forest, gbm, ert and neural networks, we are going to use model stacking. The stacked model generated the best result on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = H2OStackedEnsembleEstimator(training_frame=train_s, \n",
    "                                    validation_frame=valid_s, \n",
    "                                    base_models=[rf_model, ert_model, \n",
    "                                                 gbm_model,nn_model])\n",
    "\n",
    "stack.train(x=X,\n",
    "            y=y,\n",
    "            training_frame=train_b,\n",
    "            validation_frame=valid_b)\n",
    "\n",
    "\n",
    "stack_preds1_test = stack.predict(test_final)\n",
    "\n",
    "gen_submission(stack_preds1_test,\"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown(prompt=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
